{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ac8f1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, mean_squared_error\n",
    "import torch\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import EarlyStoppingCallback\n",
    "import random\n",
    "from datasets import ClassLabel\n",
    "from pathlib import Path\n",
    "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
    "#from transformers import logging as hf_logging\n",
    "#hf_logging.set_verbosity(hf_logging.ERROR)\n",
    "#transformers.logging.set_verbosity_error()\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import *\n",
    "from pytorch_forecasting import TimeSeriesDataSet\n",
    "# import pytorch_lightning as pl\n",
    "import lightning.pytorch as pl\n",
    "\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer import *\n",
    "import time\n",
    "# import ciso8601\n",
    "from pytorch_forecasting.models.rnn import RecurrentNetwork\n",
    "from pytorch_forecasting.models.deepar import DeepAR\n",
    "from pytorch_forecasting.models import NBeats\n",
    "from pytorch_forecasting.models.nhits import NHiTS\n",
    "from pytorch_forecasting.metrics import *\n",
    "import os\n",
    "import calendar\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, MaxAbsScaler, RobustScaler\n",
    "def get_scaler(scaler):\n",
    "    scalers = {\n",
    "        \"minmax\": MinMaxScaler,\n",
    "        \"standard\": StandardScaler,\n",
    "        \"maxabs\": MaxAbsScaler,\n",
    "        \"robust\": RobustScaler,\n",
    "    }\n",
    "    return scalers.get(scaler.lower())()\n",
    "scaler = get_scaler('minmax')\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import logging\n",
    "# logging.getLogger('lightning').setLevel(0)\n",
    "# logging.getLogger(\"pytorch_lightning\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"lightning.pytorch.utilities.rank_zero\").setLevel(logging.WARNING)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "389d6991",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "from plotly.offline import iplot, plot\n",
    "def plot_dataset(outdir, df, month):\n",
    "    data = []\n",
    "    value = go.Scatter(\n",
    "        x=df.index, y=df['target'].values,\n",
    "        mode=\"lines\", name=\"target\", marker=dict(), text=df.index, line=dict(color=\"black\"),\n",
    "    )\n",
    "    data.append(value)\n",
    "    \n",
    "    value = go.Scatter(\n",
    "        x=df.index,y=df['pred'].values,\n",
    "        mode=\"lines\",name=\"pred\",marker=dict(),text=df.index,line=dict(color=\"red\"),\n",
    "    )\n",
    "    data.append(value)\n",
    "\n",
    "    layout = dict(\n",
    "        title='title',\n",
    "        xaxis=dict(title=\"Date\", ticklen=5, zeroline=False),\n",
    "        yaxis=dict(title=\"Value\", ticklen=5, zeroline=False),\n",
    "    )\n",
    "\n",
    "    fig = dict(data=data, layout=layout)\n",
    "    #iplot(fig)\n",
    "    plot(fig, filename = f\"{outdir}/vistest-Month_{month}.html\", auto_open=False)\n",
    "    \n",
    "def get_end_day(month):\n",
    "    return calendar.monthrange(2014, month)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451e0396",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39852b80dd3f4cfabb72f33a1c0113f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dataset:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f7b79c0378349169ebf9a8909d98722",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "models:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6052b98eddd450b80bda5d34bdf695a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ahead:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "month:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c570b6cc10b49cbbeffca6b8a72ce1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "month:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# '../../train-test-sets/Data_Pods-Train2013:2017Pod0-Test2018Pod0/'\n",
    "DATASETS = ['Pods-Train2013:2017Pod0-Test2018Pod0']\n",
    "MODELS = ['LSTM', 'GRU', 'DeepAR', 'NBeats', 'TFT']\n",
    "AHEADS = [1, 96, 672]\n",
    "MONTHS = [1,2,3,4,5,6,7,8,9,10,11,12]\n",
    "nlags = 135#45\n",
    "TEST_YEARS = {\n",
    "    'Pods-Train2014Pod0-Test2015Pod0':2015,\n",
    "    'Pods-Train2013:2017Pod0-Test2018Pod0':2018,\n",
    "}\n",
    "\n",
    "for dataset in tqdm(DATASETS, desc='dataset', leave=True):\n",
    "    for modelname in tqdm(MODELS, desc='models', leave=False):\n",
    "        for ahead in tqdm(AHEADS, desc='ahead', leave=False):\n",
    "            SAVEDIR = f'../../trained-models/Data_{dataset}/Model_{modelname}/Loss_CrossEntropy/Lags_45/Prediction_point_{ahead}'\n",
    "            \n",
    "            # load model\n",
    "            model_dict = {\n",
    "                'TFT': TemporalFusionTransformer,\n",
    "                'LSTM': RecurrentNetwork,\n",
    "                'GRU': RecurrentNetwork,\n",
    "                'DeepAR': DeepAR,\n",
    "                'NBeats': NBeats,\n",
    "                'NHits': NHiTS\n",
    "            }\n",
    "            model = model_dict[modelname].load_from_checkpoint(SAVEDIR + \"/model.ckpt\")\n",
    "            \n",
    "            # load data\n",
    "            test = pd.read_parquet(f\"{SAVEDIR.replace('trained-models','train-test-sets').replace(modelname,'Others')}/test.pqt\")#.head(1000)\n",
    "            test['date'] = pd.to_datetime(test['date'])\n",
    "            test['year'] = [x.year for x in test['date']]\n",
    "            test['month'] = [x.month for x in test['date']]\n",
    "            test['day'] = [x.day for x in test['date']]\n",
    "            test['time_idx'] = range(len(test))\n",
    "            test['group'] = 0\n",
    "            # train[['value']] = train[['value']].fillna(value=0)\n",
    "            test.dropna(inplace=True)\n",
    "            \n",
    "            for month in tqdm(MONTHS, desc='month', leave=False):\n",
    "                sub = test.loc[(test['date'] >= f\"{TEST_YEARS[dataset]}-{month}-1\") & (test['date'] <= f\"{TEST_YEARS[dataset]}-{month}-{get_end_day(month)}\")]\n",
    "                \n",
    "                #display(sub.tail())\n",
    "                prediction_length = ahead\n",
    "                max_encoder_length = nlags\n",
    "                dataset_args = dict(\n",
    "                    min_encoder_length=max_encoder_length,\n",
    "                    max_encoder_length=max_encoder_length,\n",
    "                    min_prediction_length=prediction_length,\n",
    "                    max_prediction_length=prediction_length,\n",
    "                    time_varying_known_reals = ['Tensione','PotContrImp','PotDisp','PotMax','year','month','day'],\n",
    "                    time_varying_known_categoricals = ['Pod','PuntoDispacciamento','Trattamento'],\n",
    "                    time_varying_unknown_reals= [\"value\"],\n",
    "                    add_relative_time_idx=True,\n",
    "                    add_target_scales=True,\n",
    "                    add_encoder_length=True,\n",
    "                    allow_missing_timesteps=True\n",
    "                )\n",
    "\n",
    "                if modelname == 'NBeats':\n",
    "                    dataset_args['add_relative_time_idx'] = False\n",
    "                    dataset_args['time_varying_known_reals'] = []\n",
    "                    dataset_args['time_varying_known_categoricals'] = []\n",
    "                    dataset_args['add_target_scales'] = False\n",
    "                    dataset_args['add_encoder_length'] = False\n",
    "\n",
    "                if modelname == 'NHits':\n",
    "                    dataset_args['add_relative_time_idx'] = False\n",
    "                               \n",
    "                testing = TimeSeriesDataSet(\n",
    "                    sub,\n",
    "                    group_ids=[\"group\"],\n",
    "                    target=\"value\",\n",
    "                    time_idx=\"time_idx\",\n",
    "                    **dataset_args   \n",
    "                )\n",
    "#                 validation = TimeSeriesDataSet.from_dataset(training, val, predict=False, stop_randomization=True)\n",
    "                test_dataloader = testing.to_dataloader(train=False, batch_size=32)\n",
    "                \n",
    "                #gold = torch.cat([y[0] for x, y in tqdm(iter(test_dataloader))])\n",
    "                raw_pred = model.predict(test_dataloader, trainer_kwargs=dict(accelerator=\"cpu\"))\n",
    "                raw_pred = [float(x[ahead-1]) for x in raw_pred]\n",
    "                # shift prediction\n",
    "                sub['value'] = sub['value'].shift((-1)*ahead)\n",
    "                sub = sub[np.isfinite(sub['value'])]\n",
    "                sub = sub.tail(len(raw_pred))\n",
    "                \n",
    "                sub['pred'] = raw_pred\n",
    "                sub.rename(columns={'value':'target'},inplace=True)\n",
    "                sub['target'] = sub['target'].astype(float)\n",
    "                sub['pred'] = sub['pred'].astype(float)\n",
    "                sub.index = range(len(sub))\n",
    "                \n",
    "                OUTDIR = SAVEDIR.replace('trained-models','inference')\n",
    "                Path(OUTDIR).mkdir(parents=True, exist_ok=True)\n",
    "                sub.to_csv(f\"{OUTDIR}/test-Month_{month}.csv\", index=True, header=True)\n",
    "\n",
    "                OUTDIR = SAVEDIR.replace('trained-models','visual')\n",
    "                Path(OUTDIR).mkdir(parents=True, exist_ok=True)\n",
    "                fig = plot_dataset(outdir=OUTDIR, df=sub, month=month)\n",
    "\n",
    "                #print(f\"MONTH {month}\")\n",
    "                # assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081f4703",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dcba3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a741e3f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kevinr",
   "language": "python",
   "name": "kevinr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
